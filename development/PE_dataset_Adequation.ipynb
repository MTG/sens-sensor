{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SET DIRECTORIES !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory=\"/path/to/data/directory\"\n",
    "directory=\"path/to/sens-sensor\"\n",
    "print(f\"Data directory is {data_directory}\")\n",
    "print(f\"Working directory is {directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARAUS-extended dataset generation - preparing original ARAUS\n",
    "This script adequates the augmented audios and the data csv from ARAUS dataset so that it is prepared to generate the new ARAUS-extended dataset.\n",
    "responses.csv provided by ARAUS authors contains the data associated with the augmented soundscapes (participant answers, features of the audio, fold to which the audio belongs, base soundscape and masker used for the augmentation...).\n",
    "However, we are included some new columns into the dataframe, so that it is complete and handy for our operations.\n",
    "1) We are addind Pleasantness and Eventfulness values calculated from the participant answers punctuations --> 2 more columns\n",
    "2) We are adding the wav gain that has to be applied to each digital signal to convert it to pressure signal in Pascals --> 1 more column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/amaiasagastimartinez/Desktop/SENS-Soundlights/code/sens-sensor\n"
     ]
    }
   ],
   "source": [
    "# Set the working directory\n",
    "import os\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from maad.util import mean_dB\n",
    "from maad.spl import pressure2leq\n",
    "\n",
    "# Imports from this project\n",
    "from development.lib.dataset_functions import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to original ARAUS dataset\n",
    "path_csv=os.path.join(data_directory,\"files/responses.csv\")\n",
    "# Path to save new adapted dataset\n",
    "saving_path=os.path.join(data_directory,\"files/responses_adapted.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ARAUS original csv file\n",
    "Obtained directly from ARAUS repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = pd.read_csv(os.path.join(directory, path_csv), dtype = {'participant':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate P and E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ground truth labels refer to the actual, true, or correct values of the target variable (or labels) in a supervised machine learning task. In other words, these are the known outcomes or responses associated with the input data points. The purpose of ground truth labels is to provide a basis for training and evaluating machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"/Users/amaiasagastimartinez/Desktop/SENS-Soundlights/code/sens-sensor/data/images/PandE_axis.png\" width=\"500\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"/Users/amaiasagastimartinez/Desktop/SENS-Soundlights/code/sens-sensor/data/images/PandE_formulas.png\" width=\"700\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show images\n",
    "image1_path = f\"{data_directory}/images/PandE_axis.png\"\n",
    "image2_path = f\"{data_directory}/images/PandE_formulas.png\"\n",
    "html_code1 = f'<img src=\"{image1_path}\" width=\"500\">'\n",
    "html_code2 = f'<img src=\"{image2_path}\" width=\"700\">'\n",
    "display(HTML(html_code1))\n",
    "display(HTML(html_code2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Weights for ISO pleasantness:\n",
    "- Pleasant: 1\n",
    "- Eventful: 0\n",
    "- Chaotic: -sqrt(2)/2\n",
    "- Vibrant: sqrt(2)/2\n",
    "- Uneventful: 0\n",
    "- Calm: sqrt(2)/2\n",
    "- Annoying: -1\n",
    "- Monotonous: -sqrt(2)/2\n",
    "\n",
    "Weights for ISO eventfulness:\n",
    "- Pleasant: 0\n",
    "- Eventful: 1\n",
    "- Chaotic: sqrt(2)/2\n",
    "- Vibrant: sqrt(2)/2\n",
    "- Uneventful: -1\n",
    "- Calm: -sqrt(2)/2\n",
    "- Annoying: 0\n",
    "- Monotonous: -sqrt(2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27255, 162)        participant  fold_r                          soundscape  \\\n",
      "0      ARAUS_00001      -1  R0091_segment_binaural_44100_1.wav   \n",
      "1      ARAUS_00001       1  R0079_segment_binaural_44100_1.wav   \n",
      "2      ARAUS_00001       1  R0056_segment_binaural_44100_2.wav   \n",
      "3      ARAUS_00001       1  R0046_segment_binaural_44100_2.wav   \n",
      "4      ARAUS_00001       1  R0092_segment_binaural_44100_1.wav   \n",
      "...            ...     ...                                 ...   \n",
      "27250  ARAUS_10005       0    R1007_segment_binaural_44100.wav   \n",
      "27251  ARAUS_10005       0    R1006_segment_binaural_44100.wav   \n",
      "27252  ARAUS_10005       0    R1008_segment_binaural_44100.wav   \n",
      "27253  ARAUS_10005       0    R1007_segment_binaural_44100.wav   \n",
      "27254  ARAUS_10005      -1  R0091_segment_binaural_44100_1.wav   \n",
      "\n",
      "                       masker  smr  stimulus_index  time_taken  is_attention  \\\n",
      "0           silence_00001.wav    0               1      98.328             0   \n",
      "1           silence_00001.wav    6               2      77.446             0   \n",
      "2             water_00047.wav   -3               3      67.102             0   \n",
      "3           traffic_00006.wav    6               4      56.640             0   \n",
      "4           traffic_00016.wav   -6               5      51.311             0   \n",
      "...                       ...  ...             ...         ...           ...   \n",
      "27250       traffic_10001.wav    0              47      43.005             0   \n",
      "27251       silence_10001.wav    0              48      34.629             0   \n",
      "27252  construction_10001.wav    0              49      31.484             0   \n",
      "27253       silence_10001.wav    0              50      35.533             0   \n",
      "27254       silence_10001.wav    0              51      37.181             0   \n",
      "\n",
      "       pleasant  eventful  ...  M06300_0_r  M08000_0_r  M10000_0_r  \\\n",
      "0             5         4  ...   51.930000   47.730000   43.570000   \n",
      "1             5         2  ...   48.010000   41.930000   29.460000   \n",
      "2             4         2  ...   56.690000   57.960000   58.800000   \n",
      "3             5         4  ...   36.870000   35.130000   30.940000   \n",
      "4             5         4  ...   42.320000   48.090000   35.910000   \n",
      "...         ...       ...  ...         ...         ...         ...   \n",
      "27250         3         4  ...   28.881245   24.801626   23.051411   \n",
      "27251         2         5  ...   42.915951   40.051964   37.771725   \n",
      "27252         1         4  ...   44.829071   41.334560   38.121883   \n",
      "27253         5         2  ...   27.597666   23.449919   22.192390   \n",
      "27254         2         5  ...   51.930000   47.730000   43.570000   \n",
      "\n",
      "       M12500_0_r  M16000_0_r  M20000_0_r    Leq_L_r    Leq_R_r  \\\n",
      "0       37.400000   30.380000   14.760000  85.172757  89.614971   \n",
      "1       21.140000   19.280000   22.170000  68.205627  68.885104   \n",
      "2       56.370000   50.650000   42.600000  74.789701  75.876626   \n",
      "3       26.200000   22.140000   15.740000  68.045045  70.963026   \n",
      "4       29.320000   23.930000   18.430000  77.314983  81.262421   \n",
      "...           ...         ...         ...        ...        ...   \n",
      "27250   21.362434   18.760216   14.550753  65.248280  67.034565   \n",
      "27251   34.632870   27.016665   31.888105  69.411266  71.075758   \n",
      "27252   31.483295   24.891455   21.321941  78.966513  78.857925   \n",
      "27253   20.955580   18.613720   14.485429  64.532490  66.833307   \n",
      "27254   37.400000   30.380000   14.760000  85.172757  89.614971   \n",
      "\n",
      "       P_ground_truth  E_ground_truth  \n",
      "0        6.035534e-01        0.207107  \n",
      "1        4.571068e-01       -0.500000  \n",
      "2        3.535534e-01       -0.250000  \n",
      "3        4.571068e-01       -0.189340  \n",
      "4        5.303301e-01       -0.116117  \n",
      "...               ...             ...  \n",
      "27250   -2.299347e-17        0.207107  \n",
      "27251   -3.964466e-01        0.560660  \n",
      "27252   -9.267767e-01        0.383883  \n",
      "27253    6.338835e-01       -0.573223  \n",
      "27254   -1.338835e-01        0.926777  \n",
      "\n",
      "[27255 rows x 162 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define attributes to extract from dataframes\n",
    "attributes = ['pleasant', 'eventful', 'chaotic', 'vibrant', 'uneventful', 'calm', 'annoying', 'monotonous'] \n",
    "# Define weights for each attribute in attributes in computation of ISO Pleasantness\n",
    "ISOPl_weights = [1,0,-np.sqrt(2)/2,np.sqrt(2)/2, 0, np.sqrt(2)/2,-1,-np.sqrt(2)/2] \n",
    "# Define weights for each attribute in attributes in computation of ISO Eventfulness\n",
    "ISOEv_weights = [0,1,np.sqrt(2)/2,np.sqrt(2)/2, -1, -np.sqrt(2)/2,0,-np.sqrt(2)/2] \n",
    "# Copy \n",
    "responses_PE = responses.copy() \n",
    "# These are normalised ISO Pleasantness values (in [-1,1])\n",
    "responses_PE['P_ground_truth'] = ((responses[attributes] * ISOPl_weights).sum(axis=1)/(4+np.sqrt(32))).values\n",
    "# These are normalised ISO Eventfulness values (in [-1,1])\n",
    "responses_PE['E_ground_truth'] = ((responses[attributes] * ISOEv_weights).sum(axis=1)/(4+np.sqrt(32))).values\n",
    "print(responses_PE.shape, responses_PE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wav gains for each augmented soundscape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ARAUS dataset responses.csv constitute the dataset of +25k augmented soundscapes labeled with psychoacoustic and acoustic parametres. Among these, we can find Leq_r, which constitutes the Leq of channel R for each audio.\n",
    "\n",
    "In order to generate certain features (the ones we call \"ARAUS features\" as they aim to replicate the original ARAUS features), it is needed to know the gain or calibration factor that was applyied to the wav files (audios) in order to get the specified Leq. This linear gain (that converts wav to Peak-Pascals), one for each audio, is calculated in this section, and it must be stored. \n",
    "\n",
    "For the other two set of features (the ones we call \"Freesound features\" and for the CLAP embedding generation), the audios need to be coherent between each other in terms of energy, meaning that audios that were played with less volume, should have less amplitude than those who were played with higher volume. The factor that gives us this proportionate relation is the gain mentioned in the paragraph above. Therefore, this gain value is also needed for this set of features.\n",
    "\n",
    "This gain is stored in the new csv, in a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing original augmented soundscapes\n",
    "audioFolderPath=os.path.join(data_directory,\"soundscapes_augmented\")\n",
    "print(f\"Audio folder path \", audioFolderPath)\n",
    "# Prepare output dataframe\n",
    "columns=responses_PE.columns\n",
    "newDF=pd.DataFrame(columns=columns)\n",
    "newDF.insert(loc=6, column='wav_gain', value=None)\n",
    "# Go over all the audio files in the given directory \n",
    "count_clip=0\n",
    "count_total=0\n",
    "clipping=[]\n",
    "# Go over each audio file\n",
    "files = sorted(os.listdir(audioFolderPath))\n",
    "files.sort()\n",
    "for file in files:\n",
    "    print(file)\n",
    "    if file.endswith(\".mp3\") or file.endswith(\".wav\"):\n",
    "        print(\"file \", file)\n",
    "        print(\"count total \", count_total)\n",
    "        # Find the row in responses.csv corresponding to current audio\n",
    "        audio_path = os.path.join(data_directory, \"soundscapes_augmented\",file)\n",
    "        file_split = file.split(\"_\")\n",
    "        file_fold = int(file_split[1])\n",
    "        file_participant = \"ARAUS_\" + file_split[3]\n",
    "        file_stimulus = int(file_split[5].split(\".\")[0])\n",
    "        audio_info_aug = responses_PE[responses_PE[\"fold_r\"] == file_fold]\n",
    "        audio_info_aug = audio_info_aug[\n",
    "            audio_info_aug[\"stimulus_index\"] == file_stimulus\n",
    "        ]\n",
    "        audio_info_aug = audio_info_aug[\n",
    "            audio_info_aug[\"participant\"] == file_participant\n",
    "        ]\n",
    "        # Get the original Leq of this audio \n",
    "        true_Leq=audio_info_aug[\"Leq_R_r\"].values[0]\n",
    "        # Load the stereo audio file\n",
    "        audio_r,fs=load(audio_path, wav_calib=1.0, ch=1)\n",
    "        audio_l,fs=load(audio_path, wav_calib=1.0, ch=0)\n",
    "        # Calculate gain from true Leq and \"raw\" Leq\n",
    "        rawR_Leq=mean_dB(pressure2leq(audio_r, fs, 0.125))\n",
    "        gain_dB=true_Leq-rawR_Leq\n",
    "        gain=10**(gain_dB/20)\n",
    "        # Add gain info\n",
    "        audio_info_aug[\"wav_gain\"]=gain\n",
    "        # Add audio file name\n",
    "        audio_info_aug[\"file\"]=file.split(\".\")[0]\n",
    "        newDF = pd.concat([newDF, audio_info_aug], ignore_index=True)\n",
    "        # Prepare next iteration\n",
    "        count_total=count_total+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save new generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF.to_csv(os.path.join(data_directory,saving_path), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "araus-mac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
